{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d22bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchnlp.encoders.text import StaticTokenizerEncoder, stack_and_pad_tensors, pad_tensor\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from time import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f2549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd98ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBSADataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          padding='max_length',\n",
    "          return_token_type_ids=False,\n",
    "          max_length=self.max_len,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "          truncation='only_first'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "          'review_text': text,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd5a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df):\n",
    "    ds = TBSADataset(\n",
    "        texts=df.text.to_numpy(),\n",
    "        targets=df.sentiment.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=128\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded8b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_no_tweet.tsv', sep='\\t')\n",
    "df.sentiment += 1\n",
    "df_train, df_test = train_test_split(\n",
    "  df,\n",
    "  test_size=0.2,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "df_train, df_eval = train_test_split(\n",
    "  df_train,\n",
    "  test_size=0.2,\n",
    "  random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81dd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = create_data_loader(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9845bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = create_data_loader(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce6ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dl = create_data_loader(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259fdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c62278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBSA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TBSA, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=False)\n",
    "        \n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.out = nn.Linear(self.transformer.config.hidden_size, 3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.transformer(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask,\n",
    "        )[0][:, 0, :]\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92de9b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12200/961378687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnum_warmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnum_training_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "model = TBSA().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=int(len(train_dl) * 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff15bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dl, acc_steps=1):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    avg_losses = []\n",
    "    temp_preds = []\n",
    "    temp_targets = []\n",
    "    avg_accs = []\n",
    "    acc_losses = []\n",
    "    correct_predictions = 0\n",
    "    i = 0\n",
    "    t0 = time()\n",
    "    train_size = len(df_train)\n",
    "    for d in train_dl:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        targets = d[\"targets\"].to(device).view(-1)\n",
    "\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        preds = outputs.argmax(1, keepdim = True).view(-1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss = loss / acc_steps\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "        temp_preds += preds.cpu().tolist()\n",
    "        temp_targets += targets.cpu().tolist()\n",
    "\n",
    "        acc_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        i += 1\n",
    "        if i % acc_steps == 0:\n",
    "            losses.append(np.mean(acc_losses))\n",
    "            acc_losses = []\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        if i % (100 * acc_steps) == 0:\n",
    "            acc = 0\n",
    "            try:\n",
    "                acc = accuracy_score(temp_targets, temp_preds)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            temp_preds = []\n",
    "            temp_targets = []\n",
    "\n",
    "            avg_accs.append(acc)\n",
    "            avg_losses.append(np.mean(losses[i-100:i]))\n",
    "            print(i, 'iters, auroc, loss, time : ', avg_accs[-1], avg_losses[-1], time()-t0)\n",
    "\n",
    "    return correct_predictions.double() / train_size, np.mean(losses), avg_losses, avg_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c18abc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, eval_dl):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    temp_preds = []\n",
    "    temp_targets = []   \n",
    "    correct_predictions = 0\n",
    "    eval_size = len(df_eval)\n",
    "    with torch.no_grad():\n",
    "        for d in eval_dl:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            targets = d[\"targets\"].to(device).view(-1)\n",
    "            outputs = torch.zeros_like(targets)\n",
    "\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            preds = outputs.argmax(1, keepdim = True).view(-1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            temp_preds += preds.cpu().tolist()\n",
    "            temp_targets += targets.cpu().tolist()\n",
    "\n",
    "\n",
    "    acc = 0\n",
    "    try:\n",
    "        acc = accuracy_score(temp_targets, temp_preds)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    return correct_predictions.double() / eval_size, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7549e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, test_dl):\n",
    "    model = model.eval()\n",
    "    review_texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "    with torch.no_grad():\n",
    "        for d in test_dl:\n",
    "            texts = d[\"review_text\"]\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            preds = outputs.argmax(1, keepdim = True).view(-1)\n",
    "            review_texts.extend(texts)\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return review_texts, predictions, real_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb8732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_acc = 0\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72616686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(epoch, best_acc):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss, train_avg_losses, avg_accs = train_epoch(model, train_dl)\n",
    "    \n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    \n",
    "    val_acc, val_loss = eval_model(model, eval_dl)\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "    \n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'] += train_avg_losses\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "    return best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d83ee3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.7096875 0.7012013110518456 23.46341633796692\n",
      "Train loss 0.6748644018270931 accuracy 0.7217368961973278\n",
      "Val   loss 0.5442714143183923 accuracy 0.7882836587872559\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.8121875 0.4827631662786007 23.28145956993103\n",
      "Train loss 0.48346972502157337 accuracy 0.8111510791366907\n",
      "Val   loss 0.5431040544663707 accuracy 0.7882836587872559\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.80375 0.5017260302603245 23.578564882278442\n",
      "Train loss 0.495240148462233 accuracy 0.8060123329907503\n",
      "Val   loss 0.5385278895978005 accuracy 0.7882836587872559\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.8059375 0.4934819088876247 23.377612829208374\n",
      "Train loss 0.48639885287304396 accuracy 0.8101233299075026\n",
      "Val   loss 0.5365809346399 accuracy 0.7882836587872559\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.8153125 0.4842222927510738 23.436198234558105\n",
      "Train loss 0.4895379302687332 accuracy 0.8108941418293937\n",
      "Val   loss 0.5366865204226586 accuracy 0.7882836587872559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    run_epoch(epoch, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0362891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80936729663106\n"
     ]
    }
   ],
   "source": [
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a0fb05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.685866444605009"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da5d74ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186,  10,  66],\n",
       "       [ 49,  55,  51],\n",
       "       [ 44,  12, 744]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cab89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_text'] = df.apply(lambda x: x.text + ' [SEP] ' + x.target, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610ee6e",
   "metadata": {},
   "source": [
    "# TBSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a3b75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tb_data_loader(df):\n",
    "    ds = TBSADataset(\n",
    "        texts=df.target_text.to_numpy(),\n",
    "        targets=df.sentiment.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=128\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "219b5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "  df,\n",
    "  test_size=0.2,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "df_train, df_eval = train_test_split(\n",
    "  df_train,\n",
    "  test_size=0.2,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "train_dl = create_tb_data_loader(df_train)\n",
    "\n",
    "test_dl = create_tb_data_loader(df_test)\n",
    "\n",
    "eval_dl = create_tb_data_loader(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3c8007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#weights = torch.Tensor(compute_class_weight('balanced', [0,1,2], df_train.sentiment.values))\n",
    "#weights = weights / weights.sum()\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "model = TBSA().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-3, correct_bias=False)\n",
    "\n",
    "#scheduler = get_linear_schedule_with_warmup(\n",
    "#    optimizer,\n",
    "#    num_warmup_steps=0,\n",
    "#    num_training_steps=int(len(train_dl) * 1)\n",
    "#)\n",
    "history = defaultdict(list)\n",
    "best_acc = 0\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "884bdde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.556875 1.2376426005363463 11.841158390045166\n",
      "Train loss 1.1836741117180372 accuracy 0.5637204522096608\n",
      "Val   loss 0.9462817830424155 accuracy 0.6084275436793423\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.6184375 0.9332586687803268 11.805704832077026\n",
      "Train loss 0.9337639803769159 accuracy 0.6158787255909558\n",
      "Val   loss 0.9439062860704237 accuracy 0.6084275436793423\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.6240625 0.919695433974266 11.874210596084595\n",
      "Train loss 0.9204537028171977 accuracy 0.6228160328879754\n",
      "Val   loss 0.9325552005921641 accuracy 0.6084275436793423\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.61625 0.927557065486908 11.92819857597351\n",
      "Train loss 0.9186002216378196 accuracy 0.6228160328879754\n",
      "Val   loss 0.9888502609345221 accuracy 0.6084275436793423\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "100 iters, auroc, loss, time :  0.6159375 0.9364933133125305 11.974231481552124\n",
      "Train loss 0.923064367204416 accuracy 0.6228160328879754\n",
      "Val   loss 0.9634053476395146 accuracy 0.6084275436793423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    run_epoch(epoch, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a9ea504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8348397699260477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7507956592076185"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch=128\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f94cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8373048479868529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.752758858452138"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch=64\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d803536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8233360723089564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7414560150462578"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3737d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8134757600657354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7300259866812592"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#192\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb3b6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8356614626129828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7674470928633134"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#128\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3b53b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027937551355793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7024931239464111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#96\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7cc65fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8175842235004108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7256547521288529"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#64\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d63fd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197,  15,  50],\n",
       "       [ 33,  78,  44],\n",
       "       [ 55,  28, 717]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c42b893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299096138044372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7577898094622112"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#128\n",
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea6a561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8069022185702547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7206864594941901"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_review_texts, y_pred, y_test = get_predictions(model, test_dl)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d33e5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    592\n",
       "0    250\n",
       "1    131\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1b40ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0, 1, 2], y=[2 2 2 ... 2 2 2] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.3627451 , 2.51421189, 0.53520352])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_class_weight('balanced', [0,1,2], df_train.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07e2478a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3089, 0.5698, 0.1213])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e08a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
